---
layout:     post
title:      三分钟带你了解RAG
subtitle:   RAG的必要性、基本原理及思想
date:       2025-05-03
author:     谢东廷
header-img: img/post-bg-2015.jpg
catalog: true
tags:
    - Nips
    - LLM
    - artificial intelligence
---

## 前言

最近接近完成了一篇nips的工作，做的是LLM + RAG进行自动算法生成。通过完成这篇工作，我对RAG有了一些浅薄的认识，写在此处分享给大家。



## 引入 RAG 的必要性

传统大语言模型存在下列局限性：
* 知识局限与幻觉：模型依赖预训练数据，知识范围受限于训练时的语料，可能生成不准确或虚构内容（即“幻觉”），尤其在处理最新信息或专业领域问题时。

* 时效性不足：预训练知识无法动态更新，导致对实时数据的响应能力较弱。

* 专业场景需求：法律、医疗等领域的查询需要精准引用外部数据，而传统模型难以提供可靠依据。

* 计算成本：单纯扩大模型规模成本高昂，且效果提升有限。

* RAG 通过结合外部知识库和检索机制，解决上述问题，为知识密集型任务提供准确、动态的解决方案。

## RAG 的基本原理

RAG 是一种融合信息检索和自然语言生成的框架，通过引入外部知识增强生成内容的准确性和相关性。其运作依赖三个核心组件：检索器、生成器和知识库，并通过一个系统化的工作流程将它们整合。

### 检索器

检索器的主要任务是从外部知识库中查找与用户查询语义相关的文档或信息片段。它采用基于向量的语义搜索技术，将查询和文档转化为高维向量表示，通过预训练嵌入模型捉文本的语义含义。检索器通过计算查询向量与文档向量之间的相似度（例如余弦相似度或内积）来确定相关性。为了在大型知识库中高效检索，检索器使用索引技术快速定位最相似的文档。在某些场景下，检索器可能结合稀疏检索方法以提高召回率，确保尽可能找到所有相关文档，同时通过微调嵌入模型或优化检索策略提升精确率，确保检索到的文档高度相关。检索器的性能直接影响提供给生成器的上下文质量，因此在专业领域应用中常需对嵌入模型进行特定领域数据的微调。

### 生成器

生成器通常基于大型语言模型，负责根据检索到的文档和用户查询生成自然、流畅且准确的回答。它将查询与检索到的文档拼接为输入，将文档视为额外的上下文信息。生成器通过注意力机制重点关注检索文档中的相关内容，同时综合查询的意图，生成符合语义的回答。生成器的关键在于平衡对检索文档的依赖与语言生成的灵活性：过度依赖文档可能导致回答过于机械，缺乏自然性；而忽视文档则可能引发“幻觉”，生成不准确内容。为此，生成器通常通过提示工程或在特定任务数据上微调来优化，确保既能充分利用检索到的上下文，又能生成通顺的语言输出。

### 知识库

知识库是存储外部信息的数据库，供检索器查询使用。它可以包含非结构化数据或结构化数据。为适配检索需求，知识库需预先处理，例如将文档分割为较小的片段并转化为向量表示，以支持高效的语义搜索。知识库的一个显著优势是支持动态更新，可以随时添加新信息或删除过时内容，特别适合需要实时性的应用场景，如新闻摘要或技术支持。知识库的质量和覆盖范围对 RAG 的整体性能至关重要，因此需要定期进行数据清洗、去重和结构优化，以确保文档内容的全面性和相关性。

## 工作流程

RAG 的工作流程从用户输入查询开始，例如“2025 年 AI 技术趋势”。检索器首先通过嵌入模型将查询编码为向量表示，捕捉其语义意图。然后，检索器在知识库中搜索与查询向量最相似的 top-k 个文档（k 为可调参数，如 5 或 10），基于向量相似度排序。检索到的文档与查询拼接，形成生成器的输入，通常格式为“[CLS] 查询 [SEP] 文档1 [SEP] 文档2 ...”。生成器处理这一综合输入，分析检索文档的上下文并结合查询，生成自然语言回答，可能包括对文档内容的总结或直接引用。在某些实现中，系统会对生成结果进行后处理，例如检查事实一致性或添加文档引用，以提高回答的可靠性和透明度。这一流程确保 RAG 能够利用外部知识生成准确且上下文相关的回答。

## 总结

RAG 的引入解决了传统生成模型在知识范围、时效性和准确性上的局限，通过检索器、生成器和知识库的协同工作，提供了一种高效的解决方案。其基本原理依托详细的组件设计和系统化流程，核心思想则是通过外部知识增强生成能力，同时保持模块化、可更新和高可解释性。